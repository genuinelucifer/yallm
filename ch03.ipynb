{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8015306-e327-433e-9343-7957c8220278",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt', 'r') as f:\n",
    "    book_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b00839e-bdd3-4d82-8995-2e5b51e683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    " [[0.43, 0.15, 0.89], # Your (x^1)\n",
    " [0.55, 0.87, 0.66], # journey (x^2)\n",
    " [0.57, 0.85, 0.64], # starts (x^3)\n",
    " [0.22, 0.58, 0.33], # with (x^4)\n",
    " [0.77, 0.25, 0.10], # one (x^5)\n",
    " [0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94c907a-e61c-4a41-8852-fdd66ca21af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9614e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4960e-41, 0.0000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "att_scores = torch.empty(inputs.shape[0])\n",
    "att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c058074-f8f4-4942-bdfa-4febb2c23b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "for i, x_i in enumerate(inputs):\n",
    "    att_scores[i] = torch.dot(x_i, query)\n",
    "print(att_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f3808d-c09d-464f-8e21-410fe94660ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "att_scores_normalized = att_scores / att_scores.sum()\n",
    "print(att_scores_normalized)\n",
    "print(att_scores_normalized.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044039f3-27a1-43f3-b0c4-ce3ef7bc449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4494336a-4579-4ee5-8507-c14a5e86f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "att_scores_smax_naive = softmax_naive(att_scores)\n",
    "print(att_scores_smax_naive)\n",
    "print(att_scores_smax_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ff4e56-cc77-40c0-907c-7fc9b6c93c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "att_scores_smax = torch.softmax(att_scores, dim=0)\n",
    "print(att_scores_smax)\n",
    "print(att_scores_smax.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077309a1-8f4f-4fb5-a3ae-7ae53eb5ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "ctx_scores = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    ctx_scores += x_i * att_scores_smax[i]\n",
    "print(ctx_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059c87b-997c-4e0f-a67b-afdc4f36ccc7",
   "metadata": {},
   "source": [
    "## Computing context vectors for all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3575abb-b7a8-4517-8521-59be475828ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_scores = torch.empty((inputs.shape[0], inputs.shape[0]))\n",
    "att_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4456aca7-4085-491c-a7f9-55a5b94ef48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# Way 1 to multiple a matrix by its transpose\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        att_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(att_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f659cc91-35d4-4747-bf7d-339dc770e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# Way 2 to do the same\n",
    "att_scores2 = torch.empty((inputs.shape[0], inputs.shape[0]))\n",
    "att_scores2 = inputs @ inputs.T\n",
    "print(att_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47a7bbe-51ef-4dbd-8d88-2e7ab061e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "# softmax along the last dim (-1)\n",
    "att_weights = torch.softmax(att_scores2, dim=-1)\n",
    "print(att_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "588b310b-7a1d-4270-8c1e-ac36b337d3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(att_weights[0].sum())\n",
    "print(att_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f61df24-feb7-4d81-b527-b034c2acb1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_ctx_weights = att_weights @ inputs\n",
    "print(all_ctx_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b0aa25-2470-40b3-9383-5bbf78c8a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verification\n",
    "ctx_scores - all_ctx_weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7b086-34da-4d6a-8f2a-0a8772adda75",
   "metadata": {},
   "source": [
    "# Self attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ac99b0-799f-4d7f-ad01-fbb05da210d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = inputs[1]\n",
    "din = d2.shape[0]\n",
    "dout = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a3f69d3-c4c6-48ae-91e5-0a7739f6c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af15c587-b1f1-4855-92c3-4a3dfde32a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = query, k = key, v = value\n",
    "torch.manual_seed(123)\n",
    "Wq = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)\n",
    "Wk = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)\n",
    "Wv = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d537dde-ba25-4c88-8ae0-13627765a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = d2 @ Wq\n",
    "dk = d2 @ Wk\n",
    "dv = d2 @ Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e500cfa-71d4-443e-9420-6ad3c3ee1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])  ===  tensor([0.4433, 1.1419])  ===  tensor([0.3951, 1.0037])\n"
     ]
    }
   ],
   "source": [
    "print(dq, ' === ', dk, ' === ', dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c07fd0d5-b5d6-4af8-be42-5093d4ee6705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])  ===  torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ Wk\n",
    "values = inputs @ Wv\n",
    "print(keys.shape, ' === ', values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d5f9c3-5f98-45af-9e3c-931c7555dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])  ===  torch.Size([6])\n",
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "att_scores2 = dq @ keys.T\n",
    "print(att_scores2.shape, ' === ', (keys @ dq).shape)\n",
    "print(att_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87527725-38fa-4a81-bad7-43dc16aa5598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w22 =  tensor(1.8524)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "w22 = dq.dot(keys[1]);\n",
    "print(\"w22 = \", w22)\n",
    "print(w22 - att_scores2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b3d50c3-48ff-4535-84a3-1893ee048038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "dimk = keys.shape[-1]\n",
    "print(dimk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "981d8e3d-c749-4ca3-a257-50af11fdd02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])  ===  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "att_weights2 = torch.softmax(att_scores2 / dimk**0.5, dim=-1)\n",
    "print(att_weights2, ' === ', att_weights2.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a7fae87-23d3-4192-83df-41fb922fb1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "ctx_vec2  = att_weights2 @ values;\n",
    "print(ctx_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c0af9-9063-4258-af61-b73e77c6b3bd",
   "metadata": {},
   "source": [
    "# Self Attention in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02925489-ce07-4149-ad76-0a192184389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV1(torch.nn.Module):\n",
    "    def __init__(self, din, dout):\n",
    "        super().__init__()\n",
    "        self.Wq = torch.nn.Parameter(torch.rand(din, dout))\n",
    "        self.Wk = torch.nn.Parameter(torch.rand(din, dout))\n",
    "        self.Wv = torch.nn.Parameter(torch.rand(din, dout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = x @ self.Wq;\n",
    "        k = x @ self.Wk;\n",
    "        v = x @ self.Wv;\n",
    "        att_scores = q @ k.T;\n",
    "        ws = torch.softmax(att_scores / k.shape[-1]**0.5, dim=-1)\n",
    "        ctx = ws @ v\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c81332f-495b-4aae-9fd5-7bf342c7b7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa1 = SelfAttentionV1(din, dout)\n",
    "ctxvec = sa1(inputs)\n",
    "print(ctxvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d931ddc-b3ce-4fb4-b835-28c1bd13b69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verification\n",
    "ctx_vec2 - ctxvec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f30ab47d-f699-4f8c-8a18-ea720087256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(torch.nn.Module):\n",
    "    def __init__(self, din, dout, kv_bias=False):\n",
    "        super().__init__()\n",
    "        self.Wq = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wk = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wv = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.Wq(x);\n",
    "        k = self.Wk(x);\n",
    "        v = self.Wv(x);\n",
    "        att_scores = q @ k.T;\n",
    "        ws = torch.softmax(att_scores / k.shape[-1]**0.5, dim=-1)\n",
    "        ctx = ws @ v\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dee7b0b6-4085-4885-a6b9-ebc943e2039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa2 = SelfAttentionV2(din, dout)\n",
    "ctxvec = sa2(inputs)\n",
    "print(ctxvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2d20c-b014-42bf-99b2-8b6792753fb7",
   "metadata": {},
   "source": [
    "# Exercise 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba6b0d83-9bb1-4809-8e46-2c6a636645c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa2.Wq.weight.shape, sa1.Wq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ab927e8-2b9b-4ef9-8597-2859c2c1bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1.Wq = torch.nn.Parameter(sa2.Wq.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6d52db4-002e-4b34-ab07-455ad003b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa1.Wq = torch.nn.Parameter(sa2.Wq.weight.T)\n",
    "sa1.Wk = torch.nn.Parameter(sa2.Wk.weight.T)\n",
    "sa1.Wv = torch.nn.Parameter(sa2.Wv.weight.T)\n",
    "ctxvec = sa1(inputs)\n",
    "print(ctxvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f805c-ce68-49c6-8a38-dbf0c74ebe6b",
   "metadata": {},
   "source": [
    "# Causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef63243e-39f3-4db8-8aab-09d6e7d257b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa2.Wq(inputs)\n",
    "keys = sa2.Wk(inputs)\n",
    "att_scrs = queries @ keys.T\n",
    "weights = torch.softmax(att_scrs / keys.shape[1]**0.5, dim=-1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04ca75bb-cb63-43bc-b2b7-2318d069f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "ctx_len = weights.shape[0]\n",
    "print(ctx_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d28c16f8-265c-4998-be9c-a3b3a1ac356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "diagmask = torch.tril(torch.ones(ctx_len, ctx_len))\n",
    "print(diagmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb4ec5bd-41ef-4c59-986f-586408ec5d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<TrilBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Tril the weights directly\n",
    "print(torch.tril(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e342be9-5893-4389-9102-01d1284c5b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_w = diagmask * weights\n",
    "print(masked_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c501ce23-09bc-4fab-81be-17b1b5e2c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rsum = masked_w.sum(dim=-1, keepdim=True)\n",
    "masked_normed_w = masked_w / rsum\n",
    "print(masked_normed_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb8cb430-36b2-477c-833f-50b0504335de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])  ===  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "rsum1 = masked_w.sum(dim=-1, keepdim=True)\n",
    "rsum2 = masked_w.sum(dim=-1, keepdim=False)\n",
    "print(rsum1.shape, ' === ', rsum2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "478e37e2-f97f-4a21-a6a3-3d50e6672f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., -inf],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# My way to get -inf masking\n",
    "mask2 = torch.tril(torch.ones(ctx_len, ctx_len)) + torch.triu(torch.ones(ctx_len, ctx_len)*(-torch.inf), diagonal=1)\n",
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b761dd8-9a5e-4404-ad47-3cef390ec0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_w2 = mask2 * torch.abs(att_scrs)\n",
    "print(masked_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "155727d7-2980-4f32-b4a6-0095d8ae3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_normed_w2 = torch.softmax(masked_w2 / keys.shape[-1]**0.5, dim=1)\n",
    "print(masked_normed_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4da8b670-1fd5-4ccb-b200-d625e70cbb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# books way\n",
    "mask3 = torch.triu(torch.ones(ctx_len, ctx_len), diagonal=1)\n",
    "masked_w3 = att_scrs.masked_fill(mask3.bool(), -torch.inf)\n",
    "print(masked_w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28f70569-659c-4670-99f4-aa2a08650f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_normed_w3 = torch.softmax(masked_w3 / keys.shape[-1]**0.5, dim=1)\n",
    "print(masked_normed_w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8229f2d-03c3-4253-ad8b-48f3add4ba82",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f300e35b-ec3f-4ca3-a847-1a2e515f7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.5, inplace=False)\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "print(dropout)\n",
    "ones = torch.ones(6, 6)\n",
    "print(ones)\n",
    "print(dropout(ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d358322-faaf-48bb-9f75-8672bd69c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(masked_normed_w3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92ec3a50-4c4e-4dfd-bf0b-129e67b97873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedfab4a-1d74-4f04-9d6c-c043d065bf82",
   "metadata": {},
   "source": [
    "## CausalAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "846a1d81-a604-43f9-987b-eaa0ce2ad7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(torch.nn.Module):\n",
    "    def __init__(self, din, dout, ctxlen, dropout, kv_bias=False):\n",
    "        super().__init__()\n",
    "        self.dout = dout\n",
    "        self.Wq = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wk = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wv = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(ctxlen, ctxlen), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, ntok, din = x.shape\n",
    "        q = self.Wq(x);\n",
    "        k = self.Wk(x);\n",
    "        v = self.Wv(x);\n",
    "        att_scores = q @ k.transpose(1, 2); # keep batch (dim0) in place\n",
    "        att_scores.masked_fill_(self.mask.bool()[:ntok, :ntok], -torch.inf);\n",
    "        ws = torch.softmax(att_scores / k.shape[-1]**0.5, dim=-1)\n",
    "        ws = self.dropout(ws)\n",
    "        ctx = ws @ v\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3a08c899-341c-4196-a3d8-860f98861016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using this\n",
    "torch.manual_seed(123)\n",
    "ctxlen = batch.shape[1]\n",
    "ca = CausalAttention(din, dout, ctxlen, 0.0)\n",
    "ca.mask.bool()[:ctxlen, :ctxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a66be75f-0f44-4b8a-8b2e-dd2b6e19987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "ctx_vecs = ca(batch)\n",
    "print(ctx_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e3cc4-5373-46c3-9b64-a3b60a4fdb0a",
   "metadata": {},
   "source": [
    "# Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "129c13ac-0e54-48dc-a06e-8a79c9cc49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(torch.nn.Module):\n",
    "    def __init__(self, din, dout, ctxlen, dropout, num_heads, kv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([\n",
    "            CausalAttention(din, dout, ctxlen, dropout, kv_bias)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e41170d8-f22a-442b-b65a-f442867a36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 4])\n",
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "mha = MultiheadAttention(din, dout, ctxlen, 0.0, num_heads=2)\n",
    "mh_ctx = mha(batch)\n",
    "print(mh_ctx.shape)\n",
    "print(mh_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d4c7a-db08-4049-9133-20d8cee3398f",
   "metadata": {},
   "source": [
    "## Exercise 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa0341c6-b95c-4b9c-b894-0e34441992b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "mha2 = MultiheadAttention(din, 1, ctxlen, 0.5, num_heads=2)\n",
    "mh_ctx2 = mha2(batch)\n",
    "print(mh_ctx2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60e11b-f1e7-4305-b16c-bdef5a59eb5d",
   "metadata": {},
   "source": [
    "## Parallel Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d7818735-400d-4efd-a159-dde11393b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionV2(torch.nn.Module):\n",
    "    def __init__(self, din, dout, ctxlen, dropout, num_heads, kv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(dout % num_heads == 0), \"d_out MUST be multiple of num_heads\"\n",
    "        self.dout = dout\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dout // num_heads\n",
    "        self.Wq = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wk = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.Wv = torch.nn.Linear(din, dout, bias=kv_bias)\n",
    "        self.out_proj = torch.nn.Linear(dout, dout)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(ctxlen, ctxlen), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, ntok, din = x.shape\n",
    "        q = self.Wq(x);\n",
    "        k = self.Wk(x);\n",
    "        v = self.Wv(x);\n",
    "        q = q.view(b, ntok, self.num_heads, self.head_dim)\n",
    "        k = k.view(b, ntok, self.num_heads, self.head_dim)\n",
    "        v = v.view(b, ntok, self.num_heads, self.head_dim)\n",
    "\n",
    "        q = q.transpose(1, 2) # make num_heads the dim1 instead of dim2\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        att_scores = q @ k.transpose(2, 3); # keep batch (dim0) & num_heads (dim1) in place\n",
    "        att_scores.masked_fill_(self.mask.bool()[:ntok, :ntok], -torch.inf);\n",
    "        ws = torch.softmax(att_scores / k.shape[-1]**0.5, dim=-1)\n",
    "        ws = self.dropout(ws)\n",
    "        ctx = ws @ v\n",
    "        ctx = ctx.transpose(1, 2) # make num_heads the dim2\n",
    "        ctx = ctx.contiguous().view(b, ntok, self.dout)  # join dim2 and dim3 into dim2*dim3\n",
    "\n",
    "        ctx = self.out_proj(ctx) # join everything to dout*dout\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "43dba091-4ec1-406e-93d0-6ece0a4fce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# Using this\n",
    "torch.manual_seed(123)\n",
    "b, ctxlen, din = batch.shape\n",
    "dout=2\n",
    "mhav2 = MultiheadAttentionV2(din, dout, ctxlen, 0.0, 2)\n",
    "mhav2_ctx = mhav2(batch)\n",
    "print(mhav2_ctx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1d834209-3b7e-409a-a60e-bb0779e71cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mhav2_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471257a3-ee1f-4c4d-a1cb-944e4bf7fffa",
   "metadata": {},
   "source": [
    "# Exercise 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ac9cbee-1967-4ffe-b09b-0e20b32199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_gpt2 = MultiheadAttentionV2(768, 768, 1024, 0.0, num_heads = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffba8c-e406-4316-80b9-85f673725ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YALLM",
   "language": "python",
   "name": "yallm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
